{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f518a3b",
   "metadata": {},
   "source": [
    "# 4. Modeling<a id='4_Modeling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5cb5c0",
   "metadata": {},
   "source": [
    "## Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade scikit-learn imbalanced-learn\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa07810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, auc, average_precision_score, make_scorer, fbeta_score,  accuracy_score, precision_score, recall_score, fbeta_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619af685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"Data//data.csv\")\n",
    "\n",
    "#_________ Data manipulation in data wrangling part\n",
    "# Function to clean column names\n",
    "def clean_column_names(col):\n",
    "    col = col.replace(' (times)', '') # Remove ' (times)'\n",
    "    col = col.replace(' (Yuan Â¥)', '') # Remove ' (Yuan ??)'\n",
    "    col = col.replace('?', '')  # Remove question marks\n",
    "    col = col.strip()  # Remove leading and trailing spaces\n",
    "    col = col.replace(' ', '_')  # Replace spaces with underscores\n",
    "    col = col.replace('%', 'pct')  # Replace % with 'percent'\n",
    "    col = col.replace('/', '_to_')  # Replace / with '_to_'\n",
    "    col = col.replace('(', '')  # Remove opening parentheses\n",
    "    col = col.replace(')', '')  # Remove closing parentheses\n",
    "    col = re.sub(r'_([a-z])', lambda x: '_' + x.group(1).upper(), col) # Convert first letter after underscore to uppercase\n",
    "    return col\n",
    "\n",
    "# Apply the function to all column names\n",
    "df.columns = [clean_column_names(col) for col in df.columns]\n",
    "\n",
    "# Convert binary variables to categorical\n",
    "binary_columns = ['Bankrupt', 'Net_Income_Flag', 'Liability-Assets_Flag']\n",
    "df[binary_columns] = df[binary_columns].astype('category')\n",
    "\n",
    "# Remove features having same values with different names\n",
    "df.drop(columns = ['Net_Income_Flag', 'Current_Liabilities_To_Equity', 'Current_Liabilities_To_Liability'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bba93dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X = df.drop(columns=['Bankrupt'])  # Features\n",
    "y = df['Bankrupt']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(y_train.value_counts()/len(y_train))\n",
    "print(y_test.value_counts()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing Numeric Features: Min-Max Normalization\n",
    "X_train_num = X_train.select_dtypes(include=['number'])\n",
    "X_train_cat = X_train[['Liability-Assets_Flag']]\n",
    "X_test_num = X_test.select_dtypes(include=['number'])\n",
    "X_test_cat = X_test[['Liability-Assets_Flag']]\n",
    "\n",
    "# Initialize the scaler and Fit scaler with training numeric features\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train_num)\n",
    "\n",
    "# Transform the numerical features in both training and test sets\n",
    "X_train_num_scaled = scaler.transform(X_train_num)\n",
    "X_test_num_scaled = scaler.transform(X_test_num)\n",
    "\n",
    "# Convert scaled numerical features back to DataFrame\n",
    "X_train_num_scaled = pd.DataFrame(X_train_num_scaled, columns=X_train_num.columns, index=X_train.index)\n",
    "X_test_num_scaled = pd.DataFrame(X_test_num_scaled, columns=X_test_num.columns, index=X_test.index)\n",
    "\n",
    "# Combine scaled numerical features with the categorical features\n",
    "X_train_scaled = pd.concat([X_train_num_scaled, X_train_cat], axis=1)\n",
    "X_test_scaled = pd.concat([X_test_num_scaled, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07138f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Feature Generation\n",
    "stability_features = [\n",
    "    'Debt_Ratio_Pct', \n",
    "    'Borrowing_Dependency', \n",
    "    'Cash_To_Current_Liability', \n",
    "    'Fixed_Assets_To_Assets',\n",
    "    'Current_Ratio',\n",
    "    'Quick_Ratio',\n",
    "    'Total_Debt_To_Total_Net_Worth',\n",
    "    'Net_Worth_To_Assets',\n",
    "    'Long-term_Fund_Suitability_Ratio_A',\n",
    "    'Contingent_Liabilities_To_Net_Worth',\n",
    "    'Operating_Funds_To_Liability',\n",
    "    'Current_Liability_To_Assets',\n",
    "    'Current_Liability_To_Liability',\n",
    "    'Current_Liability_To_Equity',\n",
    "    'Long-term_Liability_To_Current_Assets',\n",
    "    'Retained_Earnings_To_Total_Assets',\n",
    "    'Liability_To_Equity',\n",
    "    'Degree_Of_Financial_Leverage_DFL'\n",
    "]\n",
    "\n",
    "profitability_feature = 'Net_Income_To_Total_Assets'\n",
    "activity_feature = 'Total_Asset_Turnover'\n",
    "\n",
    "# Generate New Features\n",
    "for feature in stability_features:\n",
    "    new_feature_name = f'{feature}_To_NIA'\n",
    "    X_train_scaled[new_feature_name] = (X_train_scaled[feature]+0.1) / (X_train_scaled[profitability_feature]+0.1)\n",
    "    X_test_scaled[new_feature_name] = (X_test_scaled[feature]+0.1) / (X_test_scaled[profitability_feature]+0.1)\n",
    "    \n",
    "for feature in stability_features:\n",
    "    new_feature_name = f'{feature}_To_ATO'\n",
    "    X_train_scaled[new_feature_name] = (X_train_scaled[feature]+0.1) / (X_train_scaled[activity_feature]+0.1)\n",
    "    X_test_scaled[new_feature_name] = (X_test_scaled[feature]+0.1) / (X_test_scaled[activity_feature]+0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26583d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train_scaled.select_dtypes(include=['number'])\n",
    "X_train_cat = X_train_scaled[['Liability-Assets_Flag']] \n",
    "\n",
    "X_test_num = X_test_scaled.select_dtypes(include=['number'])\n",
    "X_test_cat = X_test_scaled[['Liability-Assets_Flag']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_num)\n",
    "X_train_num_scaled = pd.DataFrame(scaler.transform(X_train_num), columns=X_train_num.columns)\n",
    "X_test_num_scaled = pd.DataFrame(scaler.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "X_train_scaled = pd.concat([X_train_num_scaled, X_train_cat.reset_index(drop=True)], axis=1)\n",
    "X_test_scaled = pd.concat([X_test_num_scaled, X_test_cat.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outlier_dummies(X_train_scaled, y_train, X_test_scaled, threshold, prop):\n",
    "    \"\"\"\n",
    "    Create outlier dummy variables for numerical features and apply to training and test data.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Training data with outlier dummy variables.\n",
    "    pd.DataFrame: Test data with outlier dummy variables.\n",
    "    \"\"\"\n",
    "    # Ensure both X_train_scaled and X_test_scaled are DataFrames\n",
    "    if not isinstance(X_train_scaled, pd.DataFrame) or not isinstance(X_test_scaled, pd.DataFrame):\n",
    "        raise ValueError(\"X_train_scaled and X_test_scaled must be pandas DataFrames.\")\n",
    "    \n",
    "    # Ensure y_train is a Series\n",
    "    if not isinstance(y_train, pd.Series):\n",
    "        raise ValueError(\"y_train must be a pandas Series.\")\n",
    "    \n",
    "    # Convert y_train to numeric if it's categorical\n",
    "    if y_train.dtype.name == 'category':\n",
    "        y_train = y_train.cat.codes\n",
    "\n",
    "    # Ensure the indices align\n",
    "    y_train = y_train.reindex(X_train_scaled.index)\n",
    "\n",
    "    # Identify numerical features\n",
    "    numerical_features = X_train_scaled.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Initialize DataFrames for dummy variables\n",
    "    X_train_dummies = X_train_scaled.copy()\n",
    "    X_test_dummies = X_test_scaled.copy()\n",
    "\n",
    "    for feature in numerical_features:\n",
    "        # Get the feature values\n",
    "        feature_train_values = X_train_scaled[feature]\n",
    "        feature_test_values = X_test_scaled[feature]\n",
    "\n",
    "        # Determine outliers\n",
    "        pos_outliers_train = feature_train_values > threshold\n",
    "        neg_outliers_train = feature_train_values < -threshold\n",
    "        pos_outliers_test = feature_test_values > threshold\n",
    "        neg_outliers_test = feature_test_values < -threshold\n",
    "        \n",
    "        # Calculate proportions\n",
    "        pos_outlier_proportion = y_train[pos_outliers_train].mean() if pos_outliers_train.any() else 0\n",
    "        neg_outlier_proportion = y_train[neg_outliers_train].mean() if neg_outliers_train.any() else 0\n",
    "\n",
    "        # Determine if outliers are significant\n",
    "        pos_outlier_significant = pos_outlier_proportion > prop * 3\n",
    "        neg_outlier_significant = neg_outlier_proportion > prop * 3\n",
    "\n",
    "        # Create dummy variables\n",
    "        if pos_outlier_significant:\n",
    "            X_train_dummies[f'{feature}_pos_outlier_D'] = np.where(pos_outliers_train, 1, 0)\n",
    "            X_test_dummies[f'{feature}_pos_outlier_D'] = np.where(pos_outliers_test, 1, 0)\n",
    "\n",
    "        if neg_outlier_significant:\n",
    "            X_train_dummies[f'{feature}_neg_outlier_D'] = np.where(neg_outliers_train, 1, 0)\n",
    "            X_test_dummies[f'{feature}_neg_outlier_D'] = np.where(neg_outliers_test, 1, 0)\n",
    "\n",
    "    return X_train_dummies, X_test_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e5606",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_dummies, X_test_with_dummies = create_outlier_dummies(\n",
    "    X_train_scaled, y_train, X_test_scaled, threshold=2, prop=0.032\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dummies = [col for col in X_train_with_dummies.columns if col.endswith('_D')]\n",
    "X_train_with_dummies['prop_dummy'] = X_train_with_dummies[Dummies].mean(axis=1)\n",
    "X_test_with_dummies['prop_dummy'] = X_test_with_dummies[Dummies].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_with_dummies.shape)\n",
    "print(X_test_with_dummies.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b75b21",
   "metadata": {},
   "source": [
    "## 4.1 Balancing Data Using SMOTE <a id='4.1 Balancing_Data_Using_SMOTE'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d00692",
   "metadata": {},
   "source": [
    "As previously discussed, our target variable is highly imbalanced, with only 3.2% of the observations being 1 and the rest being 0. If this imbalance is not addressed, issues such as bias towards the majority class and overfitting may arise during feature selection or modeling. \n",
    "\n",
    "Therefore, we will use SMOTE to address the imbalance. SMOTE is an oversampling technique that resolves the problem of data imbalance by generating additional data for the minority class in imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3417dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding categorical variable\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "X_train_cat = X_train_with_dummies[['Liability-Assets_Flag']]\n",
    "X_train_cat_encoded = encoder.fit_transform(X_train_cat)\n",
    "X_test_cat = X_test_with_dummies[['Liability-Assets_Flag']]\n",
    "X_test_cat_encoded = encoder.fit_transform(X_test_cat)\n",
    "\n",
    "# transform the encoding result to dataframe\n",
    "X_train_cat_encoded = pd.DataFrame(X_train_cat_encoded, columns=encoder.get_feature_names_out(), index=X_train_scaled.index)\n",
    "X_test_cat_encoded = pd.DataFrame(X_test_cat_encoded, columns=encoder.get_feature_names_out(), index=X_test_scaled.index)\n",
    "\n",
    "X_train_with_dummies['Liability-Assets_Flag'] = X_train_cat_encoded\n",
    "X_test_with_dummies['Liability-Assets_Flag'] = X_test_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c88de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE \n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_with_dummies, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce29bad",
   "metadata": {},
   "source": [
    "## 4.2 Model Building (1): Feature Selection Using Lasso Regression\n",
    "\n",
    "### 4.2.1 Feature Selection using Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f57aa",
   "metadata": {},
   "source": [
    "The dataset includes a total of 158 features, comprising 157 numerical features and 1 categorical feature, including the original features and newly created ones. To prevent overfitting, reduce computational costs, and improve model interpretability, it is necessary to perform feature selection. In this section, feature selection will be conducted using LASSO regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908975c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#_______ Lasso Regression\n",
    "# Find optimal alpha via grid search\n",
    "alphas = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 1]\n",
    "lasso = Lasso(random_state=42, max_iter=1000)\n",
    "\n",
    "param_grid = {'alpha': alphas}\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(f\"Optimal alpha: {best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lasso_model = grid_search.best_estimator_\n",
    "print(f\"Selected features with optimal alpha: {best_lasso_model}\")\n",
    "selected_features = X_train_balanced.columns[best_lasso_model.coef_ != 0]\n",
    "print(selected_features)\n",
    "print(f\"Number of Selected Features: {len(selected_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f949a9a",
   "metadata": {},
   "source": [
    "Through feature selection using Lasso regression, 51 features were selected for modeling, which is less than a third of the original 158 features. We will now proceed with modeling using the 51 selected features and the balanced dataset containing 10,558 observations.\n",
    "\n",
    "Next, we will visualize the selected features along with their Lasso regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c97a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizing Feature Selection Result\n",
    "features = X_train_balanced.columns\n",
    "coefficients = best_lasso_model.coef_\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Coefficient': coefficients})\n",
    "importance_df = importance_df[importance_df['Coefficient'] != 0]\n",
    "importance_df = importance_df.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "colors = ['orange' if coeff > 0 else 'skyblue' for coeff in importance_df['Coefficient']]\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "bars = plt.barh(importance_df['Feature'], importance_df['Coefficient'], color=colors)\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Feature Coefficients from Lasso Regression')\n",
    "plt.yticks(fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train_balanced[selected_features]\n",
    "X_test_selected = X_test_with_dummies[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c31e4bb",
   "metadata": {},
   "source": [
    "### 4.2.2  Model Building \n",
    "<br>\n",
    "Now, we will model using various algorithms and compare their performance to select the best-performing model. The algorithms to be used include Logistic Regression, Random Forest, SVM, XGBoost, LightGBM, and Balanced Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a5bdcc",
   "metadata": {},
   "source": [
    "#### 4.2.2.1  Evaluation Metrics Selection <a id='4.3.1  Evaluation_Metrics_Selection'></a> \n",
    "\n",
    "When evaluating the costs associated with False Negatives (FN) and False Positives (FP) in the context of bank loan or credit investment, two main aspects are crucial:\n",
    "\n",
    "* _False Negative Costs_:\n",
    "1) Principal Recovery Issues: An FN occurs when a loan is issued to a company that will actually default, but the model incorrectly predicts that it will not. This can lead to significant losses, including the inability to recover the principal and interest.\n",
    "2) Severity of Costs: The costs associated with FN can be severe. These include not only the loss of the principal and interest but also additional costs such as recovery expenses, legal fees, and damage to reputation. These costs can multiply significantly compared to the initial loss.\n",
    "\n",
    "* _False Positive Costs_:\n",
    "1) Opportunity Cost: An FP happens when a company that will not default is incorrectly predicted to default, resulting in the rejection of a loan. This can lead to opportunity costs, as the bank or investor might miss out on potential returns from this company.\n",
    "2) Relative Opportunity Cost: While FP can lead to missed opportunities, these costs are generally much smaller compared to FN costs. This is because, if the rejected company does not default, the financial impact of not lending to it might be limited. Additionally, rejecting a loan can sometimes lead to finding better investment opportunities or managing risk more effectively.\n",
    "\n",
    "* _Comparing FN and FP Costs_:\n",
    "\n",
    "1) Higher FN Costs: If FN costs are significantly higher than FP costs, it becomes crucial to minimize FNs. In this case, prioritizing recall and adjusting the model to reduce FN occurrences is essential for effective risk management. It may be acceptable to tolerate some increase in FP to reduce FN.\n",
    "2) Smaller Opportunity Cost for FP: The opportunity cost of FP might be relatively small compared to the potential financial loss from an FN. Moreover, rejecting loans that would not result in defaults might lead to safer or more profitable investments.\n",
    "\n",
    "Therefore, accuracy or metrics that evaluate recall and precision with equal weight, such as the F1 score, are insufficient as performance metrics. Considering the magnitude of costs associated with FN and FP, we will use the F4 score in this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b1ad21",
   "metadata": {},
   "source": [
    "#### 4.2.2.2  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize score function \n",
    "beta = 4 # Assign more weight to recall than precision\n",
    "f_scorer = make_scorer(fbeta_score, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2057b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(class_weight={0: 1, 1: 10}, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'max_iter': [50, 100, 150, 200, 250, 300]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logreg, \n",
    "                           param_grid=param_grid, cv=5, scoring=f_scorer, n_jobs=-1)\n",
    "grid_search.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "best_logreg = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df200a76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_logreg = best_logreg.predict(X_test_selected)\n",
    "y_prob_logreg = best_logreg.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.50\n",
    "y_pred_logreg_custom = (y_prob_logreg >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_logreg_custom))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_logreg_custom))\n",
    "print(\"\\nf Score: \", fbeta_score(y_test, y_pred_logreg_custom, beta=beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e6fc03",
   "metadata": {},
   "source": [
    "#### 4.2.2.3  Random Forest Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(estimator=rf, \n",
    "                              param_grid=param_grid_rf, \n",
    "                              cv=5, \n",
    "                              scoring=f_scorer, \n",
    "                              n_jobs=-1)\n",
    "grid_search_rf.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "best_rf = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = best_rf.predict(X_test_selected)\n",
    "y_prob_rf = best_rf.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.50\n",
    "y_pred_rf_custom = (y_prob_rf >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Best Parameters: {grid_search_rf.best_params_}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf_custom))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf_custom))\n",
    "print(\"\\nf Score: \", fbeta_score(y_test, y_pred_rf_custom, beta=beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027115ae",
   "metadata": {},
   "source": [
    "#### 4.2.2.4  Light Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e07449",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [1, 10, 20, 30],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 63, 127],\n",
    "    'min_child_samples': [10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search_lgbm = GridSearchCV(estimator=lgbm, \n",
    "                                param_grid=param_grid_lgbm, \n",
    "                                cv=5, \n",
    "                                scoring=f_scorer, \n",
    "                                n_jobs=-1)\n",
    "\n",
    "grid_search_lgbm.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "best_lgbm = grid_search_lgbm.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec0381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgbm = best_lgbm.predict(X_test_selected)\n",
    "y_prob_lgbm = best_lgbm.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.50\n",
    "y_pred_lgbm_custom = (y_prob_lgbm >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Best Parameters: {grid_search_lgbm.best_params_}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lgbm_custom))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgbm_custom))\n",
    "print(\"\\nf Score: \", fbeta_score(y_test, y_pred_lgbm_custom, beta=beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e34ee3",
   "metadata": {},
   "source": [
    "#### 4.2.2.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#__________XGBoost\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, \n",
    "                               param_grid=param_grid_xgb, \n",
    "                               cv=5, \n",
    "                               scoring=f_scorer, \n",
    "                               n_jobs=-1,\n",
    "                               verbose=1)\n",
    "\n",
    "grid_search_xgb.fit(X_train_selected, y_train_balanced)\n",
    "best_xgb = grid_search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = best_xgb.predict(X_test_selected)\n",
    "y_prob_xgb = best_xgb.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.50\n",
    "y_pred_xgb_custom = (y_prob_xgb >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Best Parameters: {grid_search_xgb.best_params_}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb_custom))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb_custom))\n",
    "print(\"\\nf Score: \", fbeta_score(y_test, y_pred_xgb_custom, beta=beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb2f2d7",
   "metadata": {},
   "source": [
    "#### 4.2.2.6  Balanced Random Forest with Unbalanced Data\n",
    "\n",
    "Balanced Random Forest is a variation of the traditional Random Forest algorithm designed to handle imbalanced datasets. In imbalanced datasets, one class (e.g., non-bankruptcy) is significantly more frequent than the other (e.g., bankruptcy). BRF addresses this by creating balanced bootstrap samples for each tree in the forest, where the minority class is oversampled, or the majority class is undersampled, to ensure an equal representation of both classes.\n",
    "\n",
    "BRF enhances performance on imbalanced data, provides a robust model, and offers better generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca090b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brf with selected features\n",
    "X_train_unbal_selected = X_train_with_dummies[selected_features]\n",
    "X_test_unbal_selected = X_test_with_dummies[selected_features]\n",
    "\n",
    "brf = BalancedRandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid_brf = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search_brf = GridSearchCV(estimator=brf, \n",
    "                               param_grid=param_grid_brf, \n",
    "                               cv=5, \n",
    "                               scoring=f_scorer, \n",
    "                               n_jobs=-1)\n",
    "\n",
    "grid_search_brf.fit(X_train_unbal_selected, y_train)\n",
    "\n",
    "\n",
    "best_brf = grid_search_brf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_brf = best_brf.predict(X_test_unbal_selected)\n",
    "y_prob_brf = best_brf.predict_proba(X_test_unbal_selected)[:, 1]\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.50\n",
    "y_pred_brf_custom = (y_prob_brf >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Best Parameters: {grid_search_brf.best_params_}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_brf_custom))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_brf_custom))\n",
    "print(\"\\nf Score: \", fbeta_score(y_test, y_pred_brf_custom, beta=beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdbc04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the results\n",
    "results = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F4 Score\": []\n",
    "}\n",
    "\n",
    "# Function to evaluate the model and store the results\n",
    "def evaluate_model(name, y_true, y_pred, beta):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    f4_score = fbeta_score(y_true, y_pred, beta=beta)\n",
    "    \n",
    "    results[\"Model\"].append(name)\n",
    "    results[\"Accuracy\"].append(report['accuracy'])\n",
    "    results[\"Precision\"].append(report['1']['precision'])  \n",
    "    results[\"Recall\"].append(report['1']['recall'])\n",
    "    results[\"F4 Score\"].append(f4_score)\n",
    "\n",
    "evaluate_model(\"Logistic Regression\", y_test, y_pred_logreg_custom, beta=4)\n",
    "evaluate_model(\"Random Forest\", y_test, y_pred_rf_custom, beta=4)\n",
    "evaluate_model(\"LightGBM\", y_test, y_pred_lgbm_custom, beta=4)\n",
    "evaluate_model(\"XGBoost\", y_test, y_pred_xgb_custom, beta=4)\n",
    "evaluate_model(\"Balanced Random Forest\", y_test, y_pred_brf_custom, beta=4)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.set_index(\"Model\", inplace=True)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c6785",
   "metadata": {},
   "source": [
    "## 4.3 Model Building (2): Feature Selection Using Random Forest\n",
    "\n",
    "### 4.3.1 Feature Selection using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d19b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_balanced.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d11f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df.sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47e58c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "threshold = 0.005\n",
    "\n",
    "importance_df_filtered = importance_df[importance_df[\"Importance\"] > threshold]\n",
    "importance_df_sorted = importance_df_filtered.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "colors = ['orange' for _ in importance_df_sorted[\"Importance\"]]\n",
    "\n",
    "plt.figure(figsize=(10, 10))  # Figure í¬ê¸°ë¥¼ ì¡°ì  (yì¶ì í­ëª©ì´ ì¤ì´ë¤ë¯ë¡ ëì´ë ì¤ì)\n",
    "plt.barh(importance_df_sorted[\"Feature\"], importance_df_sorted[\"Importance\"], \n",
    "         color=colors)\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "for index, value in enumerate(importance_df_sorted[\"Importance\"]):\n",
    "    plt.text(value, index, f'{value:.2f}', va='center', color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d3b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_rf = importance_df[importance_df['Importance'] > threshold]['Feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f80ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_features_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae66353",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d1e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train_balanced[selected_features_rf]\n",
    "X_test_selected = X_test_with_dummies[selected_features_rf]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12964c61",
   "metadata": {},
   "source": [
    "### 4.3.2  Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb25f1a6",
   "metadata": {},
   "source": [
    "#### 4.3.2.1  Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'max_iter': [50, 100, 150, 200, 250, 300, 400, 500, 1000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logreg, \n",
    "                           param_grid=param_grid, cv=5, scoring=f_scorer, n_jobs=-1)\n",
    "grid_search.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "best_logreg = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d893970",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = best_logreg.predict(X_test_selected)\n",
    "y_prob_logreg = best_logreg.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.50\n",
    "y_pred_logreg_custom = (y_prob_logreg >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_logreg_custom))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_logreg_custom))\n",
    "print(\"\\nf Score: \", fbeta_score(y_test, y_pred_logreg_custom, beta=beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577fbbf6",
   "metadata": {},
   "source": [
    "#### 4.3.2.2   Random Forest Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507ae7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(estimator=rf, \n",
    "                              param_grid=param_grid_rf, \n",
    "                              cv=5, \n",
    "                              scoring=f_scorer, \n",
    "                              n_jobs=-1)\n",
    "grid_search_rf.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "best_rf = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7404f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = best_rf.predict(X_test_selected)\n",
    "y_prob_rf = best_rf.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.50\n",
    "y_pred_rf_custom = (y_prob_rf >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Best Parameters: {grid_search_rf.best_params_}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf_custom))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf_custom))\n",
    "print(\"\\nf Score: \", fbeta_score(y_test, y_pred_rf_custom, beta=beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec826092",
   "metadata": {},
   "source": [
    "#### 4.3.2.3   Light Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d3810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [1, 10, 20, 30],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 63, 127],\n",
    "    'min_child_samples': [10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search_lgbm = GridSearchCV(estimator=lgbm, \n",
    "                                param_grid=param_grid_lgbm, \n",
    "                                cv=5, \n",
    "                                scoring=f_scorer, \n",
    "                                n_jobs=-1)\n",
    "\n",
    "grid_search_lgbm.fit(X_train_selected, y_train_balanced)\n",
    "\n",
    "best_lgbm = grid_search_lgbm.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd65d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgbm = best_lgbm.predict(X_test_selected)\n",
    "y_prob_lgbm = best_lgbm.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.50\n",
    "y_pred_lgbm_custom = (y_prob_lgbm >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Best Parameters: {grid_search_lgbm.best_params_}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lgbm_custom))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgbm_custom))\n",
    "print(\"\\nf Score: \", fbeta_score(y_test, y_pred_lgbm_custom, beta=beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c8c8f",
   "metadata": {},
   "source": [
    "#### 4.3.2.4   XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7669a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#__________XGBoost\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, \n",
    "                               param_grid=param_grid_xgb, \n",
    "                               cv=5, \n",
    "                               scoring=f_scorer, \n",
    "                               n_jobs=-1,\n",
    "                               verbose=1)\n",
    "\n",
    "grid_search_xgb.fit(X_train_selected, y_train_balanced)\n",
    "best_xgb = grid_search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75499f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = best_xgb.predict(X_test_selected)\n",
    "y_prob_xgb = best_xgb.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.50\n",
    "y_pred_xgb_custom = (y_prob_xgb >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Best Parameters: {grid_search_xgb.best_params_}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb_custom))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb_custom))\n",
    "print(\"\\nf Score: \", fbeta_score(y_test, y_pred_xgb_custom, beta=beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed2e7b",
   "metadata": {},
   "source": [
    "#### 4.3.2.5   Balanced Random Forest with Unbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brf with selected features\n",
    "X_train_unbal_selected = X_train_with_dummies[selected_features_rf]\n",
    "X_test_unbal_selected = X_test_with_dummies[selected_features_rf]\n",
    "\n",
    "brf = BalancedRandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid_brf = {\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search_brf = GridSearchCV(estimator=brf, \n",
    "                               param_grid=param_grid_brf, \n",
    "                               cv=5, \n",
    "                               scoring='f1', \n",
    "                               n_jobs=-1)\n",
    "\n",
    "grid_search_brf.fit(X_train_unbal_selected, y_train)\n",
    "\n",
    "\n",
    "best_brf = grid_search_brf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9de501",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_brf = best_brf.predict(X_test_unbal_selected)\n",
    "y_prob_brf = best_brf.predict_proba(X_test_unbal_selected)[:, 1]\n",
    "\n",
    "# Set threshold\n",
    "threshold = 0.50\n",
    "y_pred_brf_custom = (y_prob_brf >= threshold).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Best Parameters: {grid_search_brf.best_params_}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_brf_custom))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_brf_custom))\n",
    "print(\"\\nf Score: \", fbeta_score(y_test, y_pred_brf_custom, beta=beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eaac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the results\n",
    "results = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F4 Score\": []\n",
    "}\n",
    "\n",
    "evaluate_model(\"Logistic Regression\", y_test, y_pred_logreg_custom, beta=4)\n",
    "evaluate_model(\"Random Forest\", y_test, y_pred_rf_custom, beta=4)\n",
    "evaluate_model(\"LightGBM\", y_test, y_pred_lgbm_custom, beta=4)\n",
    "evaluate_model(\"XGBoost\", y_test, y_pred_xgb_custom, beta=4)\n",
    "evaluate_model(\"Balanced Random Forest\", y_test, y_pred_brf_custom, beta=4)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df.set_index(\"Model\", inplace=True)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fcffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from the first table (Lasso Regression)\n",
    "data_lasso = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'LightGBM', 'XGBoost', 'Balanced Random Forest'],\n",
    "    'Accuracy': [0.741202, 0.962610, 0.964809, 0.957478, 0.862903],\n",
    "    'Precision': [0.100775, 0.431373, 0.454545, 0.383333, 0.173516],\n",
    "    'Recall': [0.886364, 0.500000, 0.454545, 0.522727, 0.863636],\n",
    "    'F-Beta': [0.607699, 0.495364, 0.454545, 0.511780, 0.699892]\n",
    "}\n",
    "\n",
    "# Data from the second table (Random Forest)\n",
    "data_rf = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'LightGBM', 'XGBoost', 'Balanced Random Forest'],\n",
    "    'Accuracy': [0.796921, 0.961877, 0.962610, 0.960411, 0.859971],\n",
    "    'Precision': [0.127796, 0.431034, 0.433962, 0.416667, 0.173333],\n",
    "    'Recall': [0.909091, 0.568182, 0.522727, 0.568182, 0.886364],\n",
    "    'F-Beta': [0.668633, 0.557743, 0.516513, 0.556283, 0.713671]\n",
    "}\n",
    "\n",
    "# Convert dictionaries to DataFrames\n",
    "df_lasso = pd.DataFrame(data_lasso)\n",
    "df_rf = pd.DataFrame(data_rf)\n",
    "\n",
    "# Metrics and models to plot\n",
    "metrics = ['F-Beta', 'Recall', 'Precision', 'Accuracy']\n",
    "models = df_lasso['Model']\n",
    "\n",
    "# Set up the bar width and positions\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(models))\n",
    "\n",
    "# Colors\n",
    "colors_lasso = 'skyblue'\n",
    "colors_rf = 'orange'\n",
    "edgecolor = 'black'\n",
    "linewidth = 0.7\n",
    "\n",
    "# Plot each metric for both feature selection methods\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Comparison of Model Performance', fontsize=16)\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axs[i//2, i%2]\n",
    "    bars_lasso = ax.bar(index, df_lasso[metric], bar_width, color=colors_lasso, edgecolor=edgecolor, linewidth=linewidth, label='Lasso Regression')\n",
    "    bars_rf = ax.bar(index + bar_width, df_rf[metric], bar_width, color=colors_rf, edgecolor=edgecolor, linewidth=linewidth, label='Random Forest')\n",
    "\n",
    "    # Add value labels inside the top of each bar\n",
    "    for bars in [bars_lasso, bars_rf]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, height - 0.07, f'{height:.2f}', ha='center', va='bottom', fontsize=8, color='black')\n",
    "\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(metric)\n",
    "    ax.set_xticks(index + bar_width / 2)\n",
    "    ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "\n",
    "    # Show legend only in the first subplot\n",
    "    if i == 0:\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e94dc5",
   "metadata": {},
   "source": [
    "## 4.4 Insights and Conclusion\n",
    "\n",
    "1. Lasso vs. Random Forest Feature Selection:\n",
    "\n",
    "Logistic Regression benefits the most from Random Forest feature selection, improving both precision and the F4 score. This suggests Random Forest feature selection better aligns with Logistic Regressionâs strengths.\n",
    "For models like LightGBM and XGBoost, the differences are subtle but generally favor Random Forest feature selection, implying that it better captures the nuances of the data.\n",
    "\n",
    "2. Balanced Random Forest:\n",
    "\n",
    "While its accuracy is not the highest with 86.0%, its high recall(88.6%) and F4 score(0.713) highlight its effectiveness in identifying bankrupt companies. It's particularly useful if recall is prioritized in the application.\n",
    "The Random Forest feature selection further boosts its performance, making it a strong candidate for scenarios where missing a bankrupt company is costly.\n",
    "\n",
    "3. Model Recommendations:\n",
    "\n",
    "If precision is crucial (e.g., avoiding false positives): Random Forest or LightGBM would be better choices. However, in bankruptcy prediction models, considering the significant asymmetry in costs associated with incorrect predictions (False Negatives vs. False Positives), recall is of utmost importance. Therefore, it is reasonable to select the model with the highest F-score that prioritizes recall. From this perspective, Balanced Random Forest or Logistic Regression would be preferred, with Balanced Random Forest offering a better trade-off when using the F4 score.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
